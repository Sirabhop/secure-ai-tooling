# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

selfAssessment:
  title: Risk Self Assessment
  description:
    - Every organization and AI implementation is unique. We developed this self-assessment for security practitioners, to help identify which AI risks may be most relevant to you.
    - Use this assessment to start conversations and guide further research.
  personas:
    multipleChoice: true
    text:
      - Which of the following best describes your organizationâ€™s use of Generative AI models? You may select more than one option.
    answers:
      - label: personaModelCreator
        value: 1
      - label: personaModelConsumer
        value: 2
  questions:
    - id: Q1
      text:
        - Do you have robust management of all training, tuning, or evaluation data used with your models to ensure that sensitive, unauthorized, or malicious data does not enter your models?
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      personas:
        - personaModelCreator
      risks:
        - UTD
        - ISD
      relevance:
        - No
        - Maybe
    - id: Q2
      text:
        - Are you able to detect, remove, and remediate malicious or accidental changes in your training, tuning, or evaluation data?
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      personas:
        - personaModelCreator
      risks:
        - DP
      relevance:
        - No
        - Maybe
    - id: Q3
      text:
        - Is any sensitive user data used in training, tuning, or evaluating your AI models?
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      personas:
        - personaModelCreator
      risks:
        - SDD
      relevance:
        - Yes
        - Maybe
    - id: Q4
      text:
        - Do you have robust management of all user data that results from your Generative AI applications to ensure that user data is stored, processed, and used in accordance with user consents and user policies?
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      personas:
        - personaModelCreator
        - personaModelConsumer
      risks:
        - SDD
        - EDH
      relevance:
        - No
        - Maybe
    - id: Q5
      text:
        - Do you have a complete inventory of all models, datasets (for training, tuning, or evaluation), and related ML artifacts (such as code)?
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      personas:
        - personaModelCreator
        - personaModelConsumer
      risks:
        - DP
        - MST
        - MXF
      relevance:
        - No
        - Maybe
    - id: Q6
      text:
        - Do you have robust access controls on all models, datasets, and related ML artifacts to minimize, detect, and prevent unauthorized reading or copying?
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      personas:
        - personaModelCreator
        - personaModelConsumer
      risks:
        - DP
        - MXF
        - MST
      relevance:
        - No
        - Maybe
    - id: Q7
      text:
        - Are you able to ensure that all data, models, and code used to train, tune, or evaluate models cannot be tampered without detection during model development and during deployment?
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      personas:
        - personaModelCreator
      risks:
        - DP
        - MST
      relevance:
        - No
        - Maybe
    - id: Q8
      text:
        - Are the frameworks, libraries, software systems, and hardware components used in the development and deployment of your models analyzed for and protected against security vulnerabilities?
      answers:
        - label: Yes
          value: 1
        - label: 'No'
          value: 2
        - label: Maybe
          value: 3
      personas:
        - personaModelCreator
      risks:
        - DP
        - MXF
        - MDT
        - MST
      relevance:
        - No
        - Maybe
    - id: Q9
      text:
        - Do you protect your Generative AI applications and models against large-scale malicious queries from user accounts, devices, or via APIs?
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      personas:
        - personaModelCreator
        - personaModelConsumer
      risks:
        - DMS
        - MRE
      relevance:
        - No
        - Maybe
    - id: Q10
      text:
        - Are you using secure-by-default designs and coding frameworks in applications integrated with Generative AI applications?
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      personas:
        - personaModelCreator
        - personaModelConsumer
      risks:
        - IIC
      relevance:
        - No
        - Maybe
    - id: Q11
      text:
        - Do you perform adversarial testing and training on models and Generative AI applications to improve resistance to adversarial inputs?
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      personas:
        - personaModelCreator
        - personaModelConsumer
      risks:
        - IMO
        - MEV
        - PIJ
        - SDD
        - ISD
      relevance:
        - No
        - Maybe
    - id: Q12
      text:
        - Do you build or deploy Generative AI powered agents or tools that can take actions on behalf of internal or external users?
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      personas:
        - personaModelCreator
        - personaModelConsumer
      risks:
        - RA
        - PIJ
      relevance:
        - Yes
        - Maybe


vayuAssessment:
  title: Vayu Assessment
  description:
    - This assessment assigns a baseline tier from use case category and then applies risk driver checks.
    - Final tier is the maximum tier triggered by baseline gates and escalation rules.
    - Baseline tier is computed as the maximum baselineTier across selected use cases, unless a baseline gate escalates it.
  tiers:
    - label: low
      value: 1
    - label: medium
      value: 2
    - label: high
      value: 3
    - label: unacceptable
      value: 4

  useCases:
    multipleChoice: true
    text:
      - Select all that describe this AI system.
    answers:
      - label: customerEligibilityOrCreditDecisions
        value: 1
        baselineTier: high
      - label: financialCrimePrevention
        value: 2
        baselineTier: high
      - label: financialAndRiskManagementDecision
        value: 3
        baselineTier: high
      - label: customerInfluenceAndRecommendations
        value: 4
        baselineTier: medium
      - label: customerCommunicationAndService
        value: 5
        baselineTier: medium
      - label: internalCopilotWithSensitiveData
        value: 6
        baselineTier: medium
      - label: lowRiskInternalProductivity
        value: 7
        baselineTier: low
      - label: aiThatInfluencesOtherAi
        value: 8
        baselineTier: medium

  questions:
    # Baseline tier gates, short circuit order
    - id: G1
      text:
        - Prohibited characteristics
        - Does the system do social scoring for access to services, subliminal manipulation, or exploit vulnerable groups with unfair outcomes.
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      baselineGate:
        if_answer_in:
          - Yes
          - Maybe
        then_tier: unacceptable
      tags:
        - baseline
        - prohibited

    - id: G2
      text:
        - High impact domain
        - Is the system used for credit assessment or access to financial services, HR decisions, insurance pricing, trading supervision that can block transactions, critical infrastructure safety, remote biometric identification, biometric categorization on protected attributes, or emotion recognition.
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      baselineGate:
        if_answer_in:
          - Yes
          - Maybe
        then_tier: high
      tags:
        - baseline
        - highImpact

    - id: G3
      text:
        - Transparency risk
        - Could a reasonable user be unaware they are interacting with AI or AI generated content, such as chatbot, deepfake, or generated content.
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      baselineGate:
        if_answer_in:
          - Yes
          - Maybe
        then_tier: medium
      tags:
        - baseline
        - transparency

    # Risk driver group checks
    - id: RD1
      text:
        - External exposure of outputs
        - Can any output reach customers, the public, or external parties.
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      driver: externalExposure
      relevance:
        - Yes
        - Maybe
      tags:
        - riskDriver

    - id: RD2
      text:
        - Sensitive data and privacy
        - Does it process sensitive or protected personal data, infer sensitive attributes, or use personal data without full prior informed consent.
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      driver: sensitiveDataOrConsent
      relevance:
        - Yes
        - Maybe
      tags:
        - riskDriver

    - id: RD3
      text:
        - Autonomy and action taking
        - Are outputs used for critical decisions without human oversight, or does the system take actions via tools or agents, or interact with the physical environment.
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      driver: autonomyOrActions
      relevance:
        - Yes
        - Maybe
      tags:
        - riskDriver

    - id: RD4
      text:
        - Harmful or regulated content
        - Could the system handle or produce hate, harassment, deception, misinformation, violence, self harm related content, extremism, malware, or sexually explicit content.
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      driver: harmfulContent
      relevance:
        - Yes
        - Maybe
      tags:
        - riskDriver

    - id: RD5
      text:
        - Business criticality and governance
        - Does it support regulated banking functions, create material operational risk, or conflict with code of conduct or acceptable use policy.
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Maybe
          value: 3
      driver: governanceAndCriticality
      relevance:
        - Yes
        - Maybe
      tags:
        - riskDriver

    # Control check, response filtering
    - id: C1
      text:
        - Response filtering
        - Are outputs enforced through response filtering that blocks disallowed content and redacts sensitive data, with logging and monitoring.
      answers:
        - label: Yes
          value: 1
        - label: No
          value: 2
        - label: Partial
          value: 3
      control: responseFiltering
      relevance:
        - No
        - Partial
      tags:
        - control

  scoring:
    baseline:
      defaultTier: low
      useCaseBaseline:
        method:
          - If one or more use cases are selected, baseline tier is the maximum baselineTier across selections.
          - If no use case is selected, baseline tier is defaultTier.
        aggregation: max
      gateOrder:
        - G1
        - G2
        - G3
      method:
        - Compute baseline tier from use case selection.
        - Apply baseline gates in order.
        - Each matching gate sets minimum baseline tier to the gate tier.
        - Final baseline is the maximum of useCaseBaseline and any gate tiers.

    escalationRules:
      - id: E1
        text: External exposure without response filtering escalates to high.
        when:
          all:
            - driver: externalExposure
              in_answers:
                - Yes
                - Maybe
            - control: responseFiltering
              in_answers:
                - No
                - Partial
        then:
          set_minimum_tier: high

      - id: E2
        text: Harmful content potential without response filtering escalates to high.
        when:
          all:
            - driver: harmfulContent
              in_answers:
                - Yes
                - Maybe
            - control: responseFiltering
              in_answers:
                - No
                - Partial
        then:
          set_minimum_tier: high

      - id: E3
        text: Autonomy or actions without strong controls escalates to high.
        when:
          all:
            - driver: autonomyOrActions
              in_answers:
                - Yes
                - Maybe
            - control: responseFiltering
              in_answers:
                - No
                - Partial
        then:
          set_minimum_tier: high

      - id: E4
        text: Sensitive data or consent gaps set minimum tier to medium.
        when:
          any:
            - driver: sensitiveDataOrConsent
              in_answers:
                - Yes
                - Maybe
        then:
          set_minimum_tier: medium

      - id: E5
        text: Governance and criticality set minimum tier to medium.
        when:
          any:
            - driver: governanceAndCriticality
              in_answers:
                - Yes
                - Maybe
        then:
          set_minimum_tier: medium

    finalTier:
      method:
        - Start with baseline tier from scoring.baseline.
        - Apply all escalation rules.
        - Final tier is the maximum of baseline and all set_minimum_tier outcomes.
